diff --git a/src/plugins/nat/nat_ha.c b/src/plugins/nat/nat_ha.c
index 8bf07759f..f24f0e01f 100644
--- a/src/plugins/nat/nat_ha.c
+++ b/src/plugins/nat/nat_ha.c
@@ -691,6 +691,16 @@ nat_ha_sadd (ip4_address_t * in_addr, u16 in_port, ip4_address_t * out_addr,
 	     ip4_address_t * ehn_addr, u16 ehn_port, u8 proto, u32 fib_index,
 	     u16 flags, u32 thread_index, u8 is_resync)
 {
+#ifdef USE_BPF_TRACE
+  DTRACE_PROBE8 (vpp, vnet_nat_session_update_probe, 0 /* create */ ,
+		 thread_index,
+		 (u32) fib_index,
+		 (u32) proto,
+		 htonl (in_addr->as_u32),
+		 (u32) (htons (in_port)),
+		 htonl (out_addr->as_u32), (u32) (htons (out_port)));
+#endif
+
   nat_ha_event_t event;
 
   skip_if_disabled ();
diff --git a/src/plugins/nat/nat_inlines.h b/src/plugins/nat/nat_inlines.h
index 7c28919f7..1d4e3a5a8 100644
--- a/src/plugins/nat/nat_inlines.h
+++ b/src/plugins/nat/nat_inlines.h
@@ -22,6 +22,7 @@
 #include <vnet/fib/ip4_fib.h>
 #include <nat/nat.h>
 #include <nat/nat_ha.h>
+#include <vlib/bpf_tracer.h>
 
 static inline uword
 nat_pre_node_fn_inline (vlib_main_t * vm,
@@ -281,6 +282,17 @@ nat44_delete_session (snat_main_t * sm, snat_session_t * ses,
 
       nat44_delete_user_with_no_session (sm, u, thread_index);
     }
+
+#ifdef USE_BPF_TRACE
+  DTRACE_PROBE8 (vpp, vnet_nat_session_update_probe, 2 /* delete */ ,
+		 thread_index,
+		 (u32) (ses->in2out.fib_index),
+		 (u32) (ses->in2out.protocol),
+		 htonl (ses->in2out.addr.as_u32),
+		 (u32) (htons (ses->in2out.port)),
+		 htonl (ses->out2in.addr.as_u32),
+		 (u32) (htons (ses->out2in.port)));
+#endif
 }
 
 /** \brief Set TCP session state.
@@ -295,6 +307,11 @@ nat44_set_tcp_session_state_i2o (snat_main_t * sm, f64 now,
   u8 tcp_flags = vnet_buffer (b)->ip.reass.icmp_type_or_tcp_flags;
   u32 tcp_ack_number = vnet_buffer (b)->ip.reass.tcp_ack_number;
   u32 tcp_seq_number = vnet_buffer (b)->ip.reass.tcp_seq_number;
+#ifdef USE_BPF_TRACE
+  u8 old_state = ses->state;
+  bool is_add = false;
+#endif
+
   if ((ses->state == 0) && (tcp_flags & TCP_FLAG_RST))
     ses->state = NAT44_SES_RST;
   if ((ses->state == NAT44_SES_RST) && !(tcp_flags & TCP_FLAG_RST))
@@ -303,7 +320,12 @@ nat44_set_tcp_session_state_i2o (snat_main_t * sm, f64 now,
       (ses->state & NAT44_SES_O2I_SYN))
     ses->state = 0;
   if (tcp_flags & TCP_FLAG_SYN)
-    ses->state |= NAT44_SES_I2O_SYN;
+    {
+      ses->state |= NAT44_SES_I2O_SYN;
+#ifdef USE_BPF_TRACE
+      is_add = true;
+#endif
+    }
   if (tcp_flags & TCP_FLAG_FIN)
     {
       ses->i2o_fin_seq = clib_net_to_host_u32 (tcp_seq_number);
@@ -333,6 +355,21 @@ nat44_set_tcp_session_state_i2o (snat_main_t * sm, f64 now,
     }
   clib_dlist_remove (tsm->lru_pool, ses->lru_index);
   clib_dlist_addtail (tsm->lru_pool, ses->lru_head_index, ses->lru_index);
+
+#ifdef USE_BPF_TRACE
+  if (old_state != ses->state)
+    {
+      DTRACE_PROBE8 (vpp, vnet_nat_session_update_probe,
+		     (is_add) ? 0 : 1 /* create / update */ ,
+		     thread_index,
+		     (u32) (ses->in2out.fib_index),
+		     (u32) (ses->in2out.protocol),
+		     htonl (ses->in2out.addr.as_u32),
+		     (u32) (htons (ses->in2out.port)),
+		     htonl (ses->out2in.addr.as_u32),
+		     (u32) (htons (ses->out2in.port)));
+    }
+#endif
   return 0;
 }
 
diff --git a/src/vlib/CMakeLists.txt b/src/vlib/CMakeLists.txt
index 8a31af687..288fdf85b 100644
--- a/src/vlib/CMakeLists.txt
+++ b/src/vlib/CMakeLists.txt
@@ -97,6 +97,7 @@ add_vpp_library(vlib
   unix/util.c
   vmbus/vmbus.c
   ${VMBUS_SOURCE}
+  bpf_tracer.c
 
   MULTIARCH_SOURCES
   drop.c
diff --git a/src/vlib/bpf_tracer.c b/src/vlib/bpf_tracer.c
new file mode 100644
index 000000000..1e0fbe5c8
--- /dev/null
+++ b/src/vlib/bpf_tracer.c
@@ -0,0 +1,130 @@
+/*
+ * Copyright (c) 2020 Pantheon.tech and/or its affiliates.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "bpf_tracer.h"
+
+#ifdef USE_BPF_TRACE
+
+bpf_tracer_main_t bpf_tracer_main;
+
+static clib_error_t *
+bpftracer_config (vlib_main_t * vm, unformat_input_t * input)
+{
+  bpf_tracer_main_t *bm = &bpf_tracer_main;
+  bm->update_interval = 10.0;
+
+  while (unformat_check_input (input) != UNFORMAT_END_OF_INPUT)
+    {
+      if (unformat (input, "update-interval %d", &bm->update_interval))
+	;
+      else
+	return clib_error_return (0, "unknown input `%U'",
+				  format_unformat_error, input);
+    }
+  return 0;
+}
+
+static clib_error_t *
+bpf_tracer_init (vlib_main_t * vm)
+{
+  return 0;
+}
+
+static void
+update_node_runtime (vlib_main_t * vm)
+{
+  vlib_node_main_t *nm = 0;
+  vlib_main_t **stat_vms = 0, *stat_vm;
+  uword i, j;
+
+  for (i = 0; i < vec_len (vlib_mains); i++)
+    {
+      stat_vm = vlib_mains[i];
+      if (stat_vm)
+	{
+	  vec_add1 (stat_vms, stat_vm);
+	}
+    }
+
+  /*
+   * Barrier sync across stats scraping.
+   * Otherwise, the counts will be grossly inaccurate.
+   */
+  vlib_worker_thread_barrier_sync (vm);
+
+  for (j = 0; j < vec_len (stat_vms); j++)
+    {
+      stat_vm = stat_vms[j];
+      nm = &stat_vm->node_main;
+
+      for (i = 0; i < vec_len (nm->nodes); i++)
+	{
+	  vlib_node_sync_stats (stat_vm, nm->nodes[i]);
+	}
+
+      DTRACE_PROBE3 (vpp, vlib_vector_rate_probe,
+		     stat_vm->cpu_id,
+		     stat_vm->internal_node_vectors -
+		     stat_vm->internal_node_vectors_last_clear,
+		     stat_vm->internal_node_calls -
+		     stat_vm->internal_node_calls_last_clear);
+    }
+  vlib_worker_thread_barrier_release (vm);
+
+  vec_free (stat_vms);
+}
+
+static uword
+bpf_tracer_process (vlib_main_t * vm, vlib_node_runtime_t * rt,
+		    vlib_frame_t * f)
+{
+  bpf_tracer_main_t *bm = &bpf_tracer_main;
+
+  while (1)
+    {
+      /* update BPF counters */
+      update_node_runtime (vm);
+
+      /* suspend for required time interval */
+      vlib_process_suspend (vm, (f64) bm->update_interval);
+    }
+  return 0;
+}
+
+VLIB_EARLY_CONFIG_FUNCTION (bpftracer_config, "bpftracer");
+
+VLIB_INIT_FUNCTION (bpf_tracer_init) =
+{
+};
+
+/* *INDENT-OFF* */
+VLIB_REGISTER_NODE (bpf_tracer_collector, static) =
+{
+.function = bpf_tracer_process,
+.name = "bpftracer-process",
+.type = VLIB_NODE_TYPE_PROCESS,
+};
+/* *INDENT-ON* */
+
+#endif
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/vlib/bpf_tracer.h b/src/vlib/bpf_tracer.h
new file mode 100644
index 000000000..50a391379
--- /dev/null
+++ b/src/vlib/bpf_tracer.h
@@ -0,0 +1,42 @@
+/*
+ * Copyright (c) 2020 Pantheon.tech and/or its affiliates.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef included_bpf_tracer_h
+#define included_bpf_tracer_h
+
+#define USE_BPF_TRACE
+
+#ifdef USE_BPF_TRACE
+#include <sys/sdt.h>
+#include <vlib/vlib.h>
+
+typedef struct
+{
+  /* Update interval */
+  u32 update_interval;
+} bpf_tracer_main_t;
+
+#endif
+
+#endif /* included_bpf_tracer_h */
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/vlib/counter.h b/src/vlib/counter.h
index 8a5aed4c1..c3fb97b9e 100644
--- a/src/vlib/counter.h
+++ b/src/vlib/counter.h
@@ -41,6 +41,7 @@
 #define included_vlib_counter_h
 
 #include <vlib/counter_types.h>
+#include <vlib/bpf_tracer.h>
 
 /** \file
 
@@ -82,6 +83,10 @@ vlib_increment_simple_counter (vlib_simple_counter_main_t * cm,
 
   my_counters = cm->counters[thread_index];
   my_counters[index] += increment;
+#ifdef USE_BPF_TRACE
+  DTRACE_PROBE3 (vpp, vlib_increment_simple_counters_probe, cm->name, index,
+		 my_counters[index]);
+#endif
 }
 
 /** Set a simple counter
@@ -228,6 +233,13 @@ vlib_increment_combined_counter (vlib_combined_counter_main_t * cm,
 
   my_counters[index].packets += n_packets;
   my_counters[index].bytes += n_bytes;
+
+#ifdef USE_BPF_TRACE
+  DTRACE_PROBE2 (vpp, vlib_increment_combined_counters_packets_probe, index,
+		 my_counters[index].packets);
+  DTRACE_PROBE2 (vpp, vlib_increment_combined_counters_bytes_probe, index,
+		 my_counters[index].bytes);
+#endif
 }
 
 /** Pre-fetch a per-thread combined counter for the given object index */
diff --git a/src/vlib/drop.c b/src/vlib/drop.c
index e29195ad1..cfd4f6935 100644
--- a/src/vlib/drop.c
+++ b/src/vlib/drop.c
@@ -222,7 +222,11 @@ process_drop_punt (vlib_main_t * vm,
 
       c_index = counter_index (vm, error[0]);
       em->counters[c_index] += count;
-
+#ifdef USE_BPF_TRACE
+      DTRACE_PROBE3 (vpp, vlib_error_count_probe,
+		     em->error_strings_heap[c_index], c_index,
+		     em->counters[c_index]);
+#endif
       vlib_error_elog_count (vm, c_index, count);
     }
 
diff --git a/src/vlib/error_funcs.h b/src/vlib/error_funcs.h
index ab281ba2e..f3c95d7f8 100644
--- a/src/vlib/error_funcs.h
+++ b/src/vlib/error_funcs.h
@@ -41,6 +41,7 @@
 #define included_vlib_error_funcs_h
 
 #include <vlib/node_funcs.h>
+#include <vlib/bpf_tracer.h>
 
 always_inline void
 vlib_error_elog_count (vlib_main_t * vm, uword counter, uword increment)
@@ -65,7 +66,10 @@ vlib_error_count (vlib_main_t * vm, uword node_index,
 
   ASSERT (counter < vec_len (em->counters));
   em->counters[counter] += increment;
-
+#ifdef USE_BPF_TRACE
+  DTRACE_PROBE3 (vpp, vlib_error_count_probe, em->error_strings_heap[counter],
+		 counter, em->counters[counter]);
+#endif
   vlib_error_elog_count (vm, counter, increment);
 }
 
diff --git a/src/vlib/main.c b/src/vlib/main.c
index 2e100b24d..9e250b394 100644
--- a/src/vlib/main.c
+++ b/src/vlib/main.c
@@ -591,6 +591,38 @@ vlib_node_runtime_sync_stats (vlib_main_t * vm,
   r->perf_counter0_ticks_since_last_overflow = 0ULL;
   r->perf_counter1_ticks_since_last_overflow = 0ULL;
   r->perf_counter_vectors_since_last_overflow = 0ULL;
+
+#ifdef USE_BPF_TRACE
+  u64 clocks = n->stats_total.clocks - n->stats_last_clear.clocks;
+  u64 calls = n->stats_total.calls - n->stats_last_clear.calls;
+  u64 vectors = n->stats_total.vectors - n->stats_last_clear.vectors;
+  u64 suspends = n->stats_total.suspends - n->stats_last_clear.suspends;
+  u64 vectorspercall = (calls > 0) ? ((double) vectors / (double) calls) : 0;
+  f64 clocksperx = 0.;
+  f64 maxc = (f64) n->stats_total.max_clock;
+  u32 maxn = n->stats_total.max_clock_n;
+  f64 maxcn =
+    (n->stats_total.max_clock_n) ? (f64) n->stats_total.max_clock /
+    (f64) maxn : 0.0;
+
+  // Clocks per packet, per call or per suspend.
+  clocksperx = 0;
+  if (vectors > 0)
+    clocksperx = (f64) clocks / (f64) vectors;
+  else if (calls > 0)
+    clocksperx = (f64) clocks / (f64) calls;
+  else if (suspends > 0)
+    clocksperx = (f64) clocks / (f64) suspends;
+
+  DTRACE_PROBE10 (vpp, vlib_node_runtime_sync_stats_probe, n->name, r->node_index, calls,	// Calls
+		  vectors,	// Vectors
+		  suspends,	// Suspends
+		  clocksperx,	// Clocks
+		  vectorspercall,	// Vectors/Call
+		  maxcn,	// Max Node Clocks
+		  maxn,		// Vectors at Max
+		  maxc);	// Max Clocks
+#endif
 }
 
 always_inline void __attribute__ ((unused))
diff --git a/src/vlib/node_funcs.h b/src/vlib/node_funcs.h
index 263017d0e..714add51c 100644
--- a/src/vlib/node_funcs.h
+++ b/src/vlib/node_funcs.h
@@ -47,6 +47,7 @@
 
 #include <vppinfra/fifo.h>
 #include <vppinfra/tw_timer_1t_3w_1024sl_ov.h>
+#include <vlib/bpf_tracer.h>
 
 /** \brief Get vlib node by index.
  @warning This function will ASSERT if @c i is out of range.
@@ -1176,6 +1177,11 @@ vlib_node_increment_counter (vlib_main_t * vm, u32 node_index,
   vlib_error_main_t *em = &vm->error_main;
   u32 node_counter_base_index = n->error_heap_index;
   em->counters[node_counter_base_index + counter_index] += increment;
+#ifdef USE_BPF_TRACE
+  DTRACE_PROBE2 (vpp, vlib_node_counter_probe,
+		 node_counter_base_index + counter_index,
+		 em->counters[node_counter_base_index + counter_index]);
+#endif
 }
 
 /** @brief Create a vlib process
diff --git a/src/vnet/devices/devices.c b/src/vnet/devices/devices.c
index e78c5cbe4..4da65bc44 100644
--- a/src/vnet/devices/devices.c
+++ b/src/vnet/devices/devices.c
@@ -303,7 +303,13 @@ vnet_hw_interface_set_rx_mode (vnet_main_t * vnm, u32 hw_if_index,
       rt->enabled_node_state = enabled_node_state;
       if (vlib_node_get_state (vm, hw->input_node_index) !=
 	  VLIB_NODE_STATE_DISABLED)
-	vlib_node_set_state (vm, hw->input_node_index, enabled_node_state);
+	{
+	  vlib_node_set_state (vm, hw->input_node_index, enabled_node_state);
+#ifdef USE_BPF_TRACE
+	  DTRACE_PROBE2 (vpp, vnet_hw_interface_set_rx_mode_probe,
+			 hw_if_index, (u32) enabled_node_state);
+#endif
+	}
     }
 
   return 0;
diff --git a/src/vnet/fib/fib_table.c b/src/vnet/fib/fib_table.c
index ec2acc59c..4498ded33 100644
--- a/src/vnet/fib/fib_table.c
+++ b/src/vnet/fib/fib_table.c
@@ -632,7 +632,23 @@ fib_table_entry_path_add2 (u32 fib_index,
             fib_table_source_count_inc(fib_table, source);
         }
     }
-
+#ifdef USE_BPF_TRACE
+    for (ii = 0; ii < vec_len(rpaths); ii++)
+        {
+        DTRACE_PROBE6(vpp, vnet_ip_route_probe,
+            0 /*is_del*/,
+            FIB_PROTOCOL_IP6 == prefix->fp_proto /* is_ip6 */,
+            fib_index,
+            (FIB_PROTOCOL_IP4 == prefix->fp_proto) ?
+            prefix->fp_addr.ip4.as_u8 :
+            prefix->fp_addr.ip6.as_u8,
+            (u32)prefix->fp_len,
+            (FIB_PROTOCOL_IP4 == prefix->fp_proto) ?
+            rpaths[ii].frp_addr.ip4.as_u8 :
+            rpaths[ii].frp_addr.ip6.as_u8
+            );
+        }
+#endif
     return (fib_entry_index);
 }
 
@@ -651,7 +667,6 @@ fib_table_entry_path_remove2 (u32 fib_index,
     fib_node_index_t fib_entry_index;
     fib_route_path_t *rpath;
     fib_table_t *fib_table;
-
     fib_table = fib_table_get(fib_index, prefix->fp_proto);
     fib_entry_index = fib_table_lookup_exact_match_i(fib_table, prefix);
 
@@ -716,6 +731,24 @@ fib_table_entry_path_remove2 (u32 fib_index,
 
 	fib_entry_unlock(fib_entry_index);
     }
+#ifdef USE_BPF_TRACE
+    u32 ii;
+    for (ii = 0; ii < vec_len(rpaths); ii++)
+        {
+        DTRACE_PROBE6(vpp, vnet_ip_route_probe,
+            1 /*is_del*/,
+            FIB_PROTOCOL_IP6 == prefix->fp_proto /* is_ip6 */,
+            fib_index,
+            (FIB_PROTOCOL_IP4 == prefix->fp_proto) ?
+            prefix->fp_addr.ip4.as_u8 :
+            prefix->fp_addr.ip6.as_u8,
+            (u32)prefix->fp_len,
+            (FIB_PROTOCOL_IP4 == prefix->fp_proto) ?
+            rpaths[ii].frp_addr.ip4.as_u8 :
+            rpaths[ii].frp_addr.ip6.as_u8
+            );
+        }
+#endif
 }
 
 void
diff --git a/src/vnet/interface.c b/src/vnet/interface.c
index dfefdbac9..8a32110c5 100644
--- a/src/vnet/interface.c
+++ b/src/vnet/interface.c
@@ -490,6 +490,17 @@ vnet_sw_interface_set_flags_helper (vnet_main_t * vnm, u32 sw_if_index,
   si->flags &= ~mask;
   si->flags |= flags;
 
+#ifdef USE_BPF_TRACE
+  u8 *intf_name = 0;
+  intf_name =
+    format (intf_name, "%U", format_vnet_sw_interface_name, vnm, si,
+	    si->sw_if_index);
+  DTRACE_PROBE3 (vpp, vnet_sw_interface_state_probe, si->sw_if_index,
+		 (flags & VNET_SW_INTERFACE_FLAG_ADMIN_UP) ? 1 : 0,
+		 intf_name);
+  vec_free (intf_name);
+#endif
+
 done:
   return error;
 }
diff --git a/src/vnet/interface_cli.c b/src/vnet/interface_cli.c
index 2e5714c3c..1c9778a16 100644
--- a/src/vnet/interface_cli.c
+++ b/src/vnet/interface_cli.c
@@ -1763,6 +1763,12 @@ set_hw_interface_rx_placement (u32 hw_if_index, u32 queue_id,
 
   vnet_hw_interface_assign_rx_thread (vnm, hw_if_index, queue_id,
 				      thread_index);
+
+#ifdef USE_BPF_TRACE
+  DTRACE_PROBE3 (vpp, vnet_set_hw_interface_rx_placement_probe, hw_if_index,
+		 thread_index, queue_id);
+#endif
+
   vnet_hw_interface_set_rx_mode (vnm, hw_if_index, queue_id, mode);
 
   return (error);
diff --git a/src/vnet/ip-neighbor/ip_neighbor.c b/src/vnet/ip-neighbor/ip_neighbor.c
index 09b56058f..df3b59c18 100644
--- a/src/vnet/ip-neighbor/ip_neighbor.c
+++ b/src/vnet/ip-neighbor/ip_neighbor.c
@@ -16,7 +16,10 @@
  */
 
 #include <vppinfra/llist.h>
-
+#include <vlib/bpf_tracer.h>
+#ifdef USE_BPF_TRACE
+#include <arpa/inet.h>
+#endif
 #include <vnet/ip-neighbor/ip_neighbor.h>
 #include <vnet/ip-neighbor/ip4_neighbor.h>
 #include <vnet/ip-neighbor/ip6_neighbor.h>
@@ -545,6 +548,13 @@ check_customers:
 				 fib_proto_to_link (fproto),
 				 &ipn->ipn_key->ipnk_ip,
 				 ipn->ipn_key->ipnk_sw_if_index);
+#ifdef USE_BPF_TRACE
+  DTRACE_PROBE6 (vpp, vnet_ip_neighbor_probe,
+		 0 /* is_del */ , type != IP46_TYPE_IP4 /* is_ipv6 */ ,
+		 sw_if_index,
+		 (type == IP46_TYPE_IP4) ? ip->ip4.as_u8 : ip->ip6.as_u8,
+		 mac->bytes, (u32) flags);
+#endif
   return 0;
 }
 
@@ -572,7 +582,13 @@ ip_neighbor_del (const ip46_address_t * ip, ip46_type_t type, u32 sw_if_index)
     return (VNET_API_ERROR_NO_SUCH_ENTRY);
 
   ip_neighbor_free (ipn);
-
+#ifdef USE_BPF_TRACE
+  DTRACE_PROBE6 (vpp, vnet_ip_neighbor_probe,
+		 1 /* is_del */ , type != IP46_TYPE_IP4 /* is_ipv6 */ ,
+		 sw_if_index,
+		 (type == IP46_TYPE_IP4) ? ip->ip4.as_u8 : ip->ip6.as_u8,
+		 ipn->ipn_mac.bytes, ipn->ipn_flags);
+#endif
   return (0);
 }
 
diff --git a/src/vnet/ip/ip_interface.c b/src/vnet/ip/ip_interface.c
index 48c20a6cf..d8e62d1ae 100644
--- a/src/vnet/ip/ip_interface.c
+++ b/src/vnet/ip/ip_interface.c
@@ -86,7 +86,11 @@ ip_interface_address_add (ip_lookup_main_t * lm,
     (hi != ~0) ? hi : ai;
 
   *result_if_address_index = ai;
-
+#ifdef USE_BPF_TRACE
+  DTRACE_PROBE5 (vpp, vnet_ip_address_probe,
+		 0 /* is_del */ , lm->is_ip6, sw_if_index, (u8 *) addr_fib,
+		 address_length);
+#endif
   return (NULL);
 }
 
@@ -133,6 +137,11 @@ ip_interface_address_del (ip_lookup_main_t * lm,
   mhash_unset (&lm->address_to_if_address_index, addr_fib,
 	       /* old_value */ 0);
   pool_put (lm->if_address_pool, a);
+#ifdef USE_BPF_TRACE
+  DTRACE_PROBE5 (vpp, vnet_ip_address_probe,
+		 1 /* is_del */ , lm->is_ip6, sw_if_index, (u8 *) addr_fib,
+		 address_length);
+#endif
   return NULL;
 }
 
diff --git a/src/vnet/ip/lookup.c b/src/vnet/ip/lookup.c
index 5d4e137fb..bb8924f91 100644
--- a/src/vnet/ip/lookup.c
+++ b/src/vnet/ip/lookup.c
@@ -284,6 +284,7 @@ vnet_ip_route_cmd (vlib_main_t * vm,
       if (is_del && 0 == vec_len (rpaths))
 	{
 	  fib_table_entry_delete (fib_index, &prefixs[i], FIB_SOURCE_CLI);
+	  // TODO ... DTRACE_PROBE for DPO ???
 	}
       else if (!is_del && 1 == vec_len (dpos))
 	{
@@ -293,6 +294,7 @@ vnet_ip_route_cmd (vlib_main_t * vm,
 					   FIB_ENTRY_FLAG_EXCLUSIVE,
 					   &dpos[0]);
 	  dpo_reset (&dpos[0]);
+	  // TODO ... DTRACE_PROBE for DPO ???
 	}
       else if (vec_len (dpos) > 0)
 	{
